

##### intern
- 在字符串常量中，默认会将对象放入常量池，也会去查看字符串常量池中是否有等于(equals)该对象的字符串；在字符串变量中，对象是会创建在堆内存中。
如果调用intern方法，会去查看字符串常量池中是否有等于该对象的字符串，如果没有则在常量池中新增该对象，并返回该对象引用；
如果有，则返回常量池中的字符串。堆内存中原有的对象由于没有引用指向它，将会通过垃圾回收器回收
```
String str1= "abc"; // 在字符串常量中
String str2= new String("abc"); // 在字符串变量中
String str3= str2.intern(); // 如果调用intern方法
assertSame(str1==str2);
assertSame(str2==str3);
assertSame(srt1==str3)

        String str5 = "abc";
        String str52 = "abc";

        if(str1==str12) {
            System.out.print("str1==str12");
        }
```

```
        long t = System.currentTimeMillis();
        String str = "";
        for (int i = 0; i < 100000; i++) {
            str += i;
        }
        System.out.println(System.currentTimeMillis() - t); // 32241 ms

        long t2= System.currentTimeMillis();
        StringBuilder stringBuilder = new StringBuilder();
        for (int i = 0; i < 100000; i++) {
            stringBuilder.append(i);
        }
        System.out.println(System.currentTimeMillis() - t2); // 2 ms


```
```
String str = "abcdef";

for(int i=0; i<1000; i++) {
      str = str + i;
}

// 编译器优化后  
// 即使使用+号作为字符串的拼接，也一样可以被编译器优化成StringBuilder的方式。
// 但再细致些，你会发现在编译器优化的代码中，每次循环都会生成一个新的StringBuilder实例，同样也会降低系统的性能。
String str = "abcdef";

for(int i=0; i<1000; i++) {
        	  str = (new StringBuilder(String.valueOf(str))).append(i).toString();
}
```


##### regex 回溯问题
- 正则表达式使用一些特定的元字符来检索、匹配以及替换符合规则的字符串。
构造正则表达式语法的元字符，由普通字符、标准字符、限定字符（量词）、定位字符（边界字符）组成
- 匹配模式
    - 贪婪模式 会导致回溯问题， 顾名思义，就是在数量匹配中，如果单独使用+、 ? 、* 或{min,max} 等量词，正则表达式会匹配尽可能多的内容
    - 懒惰模式 后面加 "?"
    - 独占模式 后面加 "+"
- 避免回溯的方法就是：使用懒惰模式和独占模式。
```
什么是回溯
假如现在待匹配的字符串是：1111a

正则表达式为：[\d,a]+a

此时对[\d,a]是默认的贪婪模式，匹配的大致流程：
第一个字符1是否满足[\d,a]，满足
第二个字符1是否满足[\d,a]，满足
…..
最后一个字符a是否满足[\d,a]，满足
后面没有字符匹配正则表达式最后的a了，匹配失败，！！回溯！！
回到最后一个字符，匹配正则表达式的a，匹配成功（此处如果匹配失败，会继续回到倒数第二个字符去匹配，依次类推，所以如果字符串很长，会出现回溯很多）

如果是非贪婪模式（勉强模式）：[\d,a]+？a
首先第一个字符匹配[\d,a]，因为是非贪婪的，所以第二个字符就开始匹配a，匹配失败，再用第二个字符匹配[\d,a]，依次类推

独占模式：[\d,a]++a
以前都没听过或者使用过这个模式，挺新鲜的，它其实就是不会回溯的贪婪模式，回头看贪婪模式的步骤，如果是独占模式，在倒数第二步匹配失败的时候，就会直接返回匹配失败，不会再回溯去尝试，所以其实是个很实用很高效的模式
```


##### ArrayList vs LinkedList

- ArrayList elementData被关键字transient修饰
    - ArrayList的数组是基于动态扩增 不是所有被分配的内存空间都存储了数据 为了避免这些没有存储数据的内存空间被序列化 
    - 内部提供了两个私有方法writeObject以及readObject来自我完成序列化与反序列化，从而在序列化与反序列化数组时节省了空间和时间
- ArrayList新增元素
    - 加到数组末尾 可能扩容，不会额外的有元素复制排序过程
        - 如果不会触发扩容，ArrayList在大量新增元素的场景下，性能并不会变差，反而比其他List集合的性能要好
    - 添加元素到任意位置 可能扩容，导致在该位置后的所有元素都需要重新排列
- ArrayList删除元素
    - 每次都要进行数组的重组，并且删除的元素位置越靠前，数组重组的开销就越大
  
- LinkedList存储数据的内存地址是不连续的，而是通过指针来定位不连续地址，因此，LinkedList不支持随机快速访问，LinkedList也就不能实现RandomAccess接口
- LinkedList添加到任意两个元素的中间位置和删除，相比ArrayList的添加操作来说，LinkedList的性能优势明显

- LinkedList在添加元素的时候，首先会通过循环查找到添加元素的位置，如果要添加的位置处于List的前半段，就从前往后找；若其位置处于后半段，就从后往前找。因此LinkedList添加元素到头部是非常高效的
- LinkedList避免用for循环，使用foreach 或 iterator
- 需要通过iterator remove的原因
```
        final void checkForComodification() {
            if (modCount != expectedModCount)
                throw new ConcurrentModificationException();
        }
```
##### Stream
- Java8中添加了一个新的接口类Stream，他和我们之前接触的字节流概念不太一样，Java8集合中的Stream相当于高级版的Iterator，他可以通过Lambda 表达式对集合进行各种非常便利、高效的聚合操作（Aggregate Operation），或者大批量数据操作 (Bulk Data Operation)
- 操作类型
    - 中间操作(间操作称为懒操作)只对操作进行了记录，即只会返回一个流，不会进行计算操作，而终结操作是实现了计算操作
    - 中间操作又可以分为无状态（Stateless）与有状态（Stateful）操作，前者是指元素的处理不受之前元素的影响，后者是指该操作只有拿到所有元素之后才能继续下去
    - 终结操作又可以分为短路（Short-circuiting）与非短路（Unshort-circuiting）操作，前者是指遇到某些符合条件的元素就可以得到最终结果，后者是指必须处理完所有元素才能得到最终结果
- 处理大数据的集合时，应该尽量考虑将应用部署在多核CPU环境下，并且使用Stream的并行迭代方式进行处理
- 在串行处理操作中
    - Stream在执行每一步中间操作时，并不会做实际的数据操作处理，而是将这些中间操作串联起来，最终由终结操作触发，生成一个数据处理链表，通过Java8中的Spliterator迭代器进行数据处理；此时，每执行一次迭代，就对所有的无状态的中间操作(StatelessOp)进行数据处理，而对有状态的中间操作，就需要迭代处理完所有的数据，再进行处理操作；最后就是进行终结操作的数据处理。
- 在并行处理操作中
    - Stream对中间操作基本跟串行处理方式是一样的，但在终结操作中，Stream将结合ForkJoin框架对集合进行切片处理，ForkJoin框架将每个切片的处理结果Join合并起来。最后就是要注意Stream的使用场景
    
##### I/O
- I/O是机器获取和交换信息的主要渠道，而流是完成I/O操作的主要方式。
- 在计算机中，流是一种信息的转换: 机器间或程序间在进行信息交换或者数据交换时，总是先将对象或数据转换为某种形式的流，再通过流的传输，到达指定机器或程序后，再将流转换为对象数据。因此，流就可以被看作是一种数据的载体，通过它可以实现数据交换和传输。

- 字节流 字符流
- 字符到字节必须经过转码，这个过程非常耗时，如果我们不知道编码类型就很容易出现乱码问题。所以I/O流提供了一个直接操作字符的接口，方便我们平时对字符进行流操作

- I/O操作分为磁盘I/O操作和网络I/O操作。前者是从磁盘中读取数据源输入到内存中，之后将读取的信息持久化输出在物理磁盘上；后者是从网络中读取信息输入到内存，最终将信息输出到网络中。但不管是磁盘I/O还是网络I/O，在传统I/O中都存在严重的性能问题

- 传统I/O的性能问题
    - 多次内存复制 数据先从外部设备复制到内核空间，再从内核空间复制到用户空间，这就发生了两次内存复制操作
    - 阻塞 InputStream的read()是一个while循环操作，它会一直等待数据读取，直到数据就绪才会返回。这就意味着如果没有数据就绪，这个读取操作将会一直被挂起，用户线程将会处于阻塞状态
        - 但在发生大量连接请求时，就需要创建大量监听线程，这时如果线程没有数据就绪就会被挂起，然后进入阻塞状态。一旦发生线程阻塞，这些线程将会不断地抢夺CPU资源，从而导致大量的CPU上下文切换，增加系统的性能开销
        
- NIO
    - 使用缓冲区优化读写流操作
        - NIO与传统 I/O 不同，它是基于块（Block）的，它以块为基本单位处理数据
        - Buffer是一块连续的内存块，是 NIO 读写数据的中转地。Channel表示缓冲数据的源头或者目的地，它用于读取缓冲或者写入数据，是访问缓冲的接口
        - 传统I/O和NIO的最大区别就是传统I/O是面向流，NIO是面向Buffer
        - Buffer可以将文件一次性读入内存再做后续处理，而传统的方式是边读文件边处理数据
    - 使用DirectBuffer减少内存复制
        - NIO的Buffer除了做了缓冲块优化之外，还提供了一个可以直接访问物理内存的类DirectBuffer。普通的Buffer分配的是JVM堆内存，而DirectBuffer是直接分配物理内存
        - 数据要输出到外部设备，必须先从用户空间复制到内核空间，再复制到输出设备，而DirectBuffer则是直接将步骤简化为从内核空间复制到外部设备，减少了数据拷贝
        - DirectBuffer申请的是非JVM的物理内存，所以创建和销毁的代价很高。DirectBuffer申请的内存并不是直接由JVM负责垃圾回收，但在DirectBuffer包装类被回收时，会通过Java Reference机制来释放该内存块
    - 避免阻塞，优化I/O操作
        - NIO很多人也称之为Non-block I/O，即非阻塞I/O，因为这样叫，更能体现它的特点
        - 传统的I/O对Socket的输入流进行读取时，读取流会一直阻塞，直到发生以下三种情况的任意一种才会解除阻塞
            ```
                有数据可读；
                连接释放；
                空指针或I/O异常。
            ```  
        - NIO发布后，通道和多路复用器这两个基本组件实现了NIO的非阻塞
            - 通道（Channel）
                - 传统I/O的数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的I/O接口从磁盘读取或写入; 最开始，在应用程序调用操作系统I/O接口时，是由CPU完成分配，这种方式最大的问题是“发生大量I/O请求时，非常消耗CPU“；之后，操作系统引入了DMA（直接存储器存储），内核空间与磁盘之间的存取完全由DMA负责，但这种方式依然需要向CPU申请权限，且需要借助DMA总线来完成数据的复制操作，如果DMA总线过多，就会造成总线冲突
                - 通道的出现解决了以上问题，Channel有自己的处理器，可以完成内核空间和磁盘之间的I/O操作
            - 多路复用器（Selector）
                - Selector是Java NIO编程的基础。用于检查一个或多个NIO Channel的状态是否处于可读、可写。
                - Selector是基于事件驱动实现的，我们可以在Selector中注册accpet、read监听事件，Selector会不断轮询注册在其上的Channel，如果某个Channel上面发生监听事件，这个Channel就处于就绪状态，然后进行I/O操作。
                - 一个线程使用一个Selector，通过轮询的方式，可以监听多个Channel上的事件。我们可以在注册Channel时设置该通道为非阻塞，当Channel上没有I/O操作时，该线程就不会一直等待了，而是会不断轮询所有Channel，从而避免发生阻塞
                - 目前操作系统的I/O多路复用机制都使用了epoll，相比传统的select机制，epoll没有最大连接句柄1024的限制。所以Selector在理论上可以轮询成千上万的客户端。
            
    - Java的传统I/O开始是基于InputStream和OutputStream两个操作流实现的，这种流操作是以字节为单位，如果在高并发、大数据场景中，很容易导致阻塞，因此这种操作的性能是非常差的。还有，输出数据从用户空间复制到内核空间，再复制到输出设备，这样的操作会增加系统的性能开销
    - 于是NIO发布，它是基于缓冲块为单位的流操作，在Buffer的基础上，新增了两个组件“管道和多路复用器”，实现了非阻塞I/O，NIO适用于发生大量I/O连接请求的场景，这三个组件共同提升了I/O的整体性能。
    
    - 来源网络待确认 (在Linux中，AIO并未真正使用操作系统所提供的异步I/O，它仍然使用poll或epoll，并将API封装为异步I/O的样子，但是其本质仍然是同步非阻塞I/O，加上第三方产品的出现，Java网络编程明显落后，所以没有成为主流)
    
    
##### 线程
- 在HotSpot VM的线程模型中，Java线程一对一映射为内核线程。Java线程的创建与销毁会消耗一定的计算机资源，增加系统的性能开销
- 大量创建线程给系统带来性能问题，内存和CPU资源将被线程抢占，如果处理不当，会发生内存溢出、CPU使用率超负荷等问题
- 确定线程数
    - CPU密集型任务 N（CPU核心数）+1
        - CPU核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用CPU的空闲时间
    - I/O密集型任务 2N
        - 线程在处理I/O的时间段内不会占用CPU来处理
    - 线程数=N（CPU核数）*（1+WT（线程等待时间）/ST（线程时间运行时间））
        - VisualVM来查看WT/ST
    - 从“N+1”和“2N”两个公式中选出一个适合的，计算出一个大概的线程数量，之后通过实际压测，逐渐往“增大线程数量”和“减小线程数量”这两个方向调整，然后观察整体的处理时间变化，最终确定一个具体的线程数量
    - 每个线程都会消耗栈空间 -Xss1M 设置每个线程的栈大小
- IO所需要的CPU资源非常少。大部分工作是分派给DMA完成的。
    - 计算机内部不只cpu一个部件 比如cpu将io事件分派给DMA(Direct Memory Access)芯片帮它完成 这样上下文切换才有真正的意义
    - cpu计算文件地址 => 委派DMA读取文件 => DMA接管总线 => CPU的A进程阻塞，挂起 => CPU切换到B进程 => DMA读取完文件后通知CPU(一个中断异常) => CPU切换回A进程操作文件   
- 实现线程主要有三种方式：轻量级进程和内核线程一对一相互映射实现的1:1线程模型、用户线程和内核线程实现的N:1线程模型以及用户线程和轻量级进程混合实现的N:M线程模型。
    - 1:1线程模型
        - 内核线程（Kernel-Level Thread, KLT）是由操作系统内核支持的线程；内核通过调度器对线程进行调度，并负责完成线程的切换
        - fork()函数创建一个子进程来代表一个内核中的线程，相当于复制了一个主进程；采用fork()创建子进程的方式来实现并行运行，会产生大量冗余数据，即占用大量内存空间，又消耗大量CPU时间用来初始化内存空间以及复制数据
        - clone()系统调用 创建轻量级进程（Light Weight Process，即LWP）；LWP是跟内核线程一对一映射的，每个LWP都是由一个内核线程支持；将部分父进程的资源的数据结构进行复制，复制内容可选，且没有被复制的资源可以通过指针共享给子进程。因此，轻量级进程的运行单元更小，运行速度更快
        - 1:1线程模型由于跟内核是一对一映射，所以在线程创建、切换上都存在用户态和内核态的切换，性能开销比较大。除此之外，它还存在局限性，主要就是指系统的资源有限，不能支持创建大量的LWP
    - N:1
        - 在用户空间完成了线程的创建、同步、销毁和调度，已经不需要内核的帮助了，也就是说在线程创建、同步、销毁的过程中不会产生用户态和内核态的空间切换
        - 于操作系统不能感知用户态的线程，因此容易造成某一个线程进行系统调用内核线程时被阻塞，从而导致整个进程被阻塞
    - N:M
        - 支持用户态线程通过LWP与内核线程连接，用户态的线程数量和内核态的LWP数量是N:M的映射关系
- java Thread
    - JDK 1.8 Thread.java 中 Thread#start 方法的实现，实际上是通过Native调用start0方法实现的；在Linux下， JVM Thread的实现是基于pthread_create实现的，而pthread_create实际上是调用了clone()完成系统调用创建线程的
    - 一个用户线程映射到一个内核线程，即1:1线程模型
    - 由于线程是通过内核调度，从一个线程切换到另一个线程就涉及到了上下文切换。
- 协程
    - 协程和线程密切相关，协程可以认为是运行在线程上的代码块，协程提供的挂起操作会使协程暂停执行，而不会导致线程阻塞
    - Kilim协程框架 通过协程框架在Java中使用协程。在有严重阻塞的场景下，协程的性能更胜一筹。其实，I/O阻塞型场景也就是协程在Java中的主要应用
    - 而Go语言是使用了N:M线程模型实现了自己的调度器，它在N个内核线程上多路复用（或调度）M个协程，协程的上下文切换是在用户态由协程调度器完成的，因此不需要陷入内核，相比之下，这个代价就很小了。
    - 可以将协程看作是一个类函数或者一块函数中的代码，我们可以在一个主线程里面轻松创建多个协程
