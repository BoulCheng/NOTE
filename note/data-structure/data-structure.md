

#### 渐进时间复杂度
- 对于一个算法，假设其问题的输入大小为n，那么我们可以用 O(n) 来表示其算法时间复杂度(time complexity)。那么，渐进时间复杂度（asymptotic time complexity）就是当n趋于无穷大的时候，O（n）得到的极限值。

- 插入排序常数比快速排序 归并排序常数小，当数据量小时可考虑使用插入排序


#### 线性结构
- 数据排成一排
```
1．集合中必存在唯一的一个"第一个元素"；
2．集合中必存在唯一的一个"最后的元素"；
3．除最后元素之外，其它数据元素均有唯一的"后继"；
4．除第一元素之外，其它数据元素均有唯一的"前驱"。
数据结构中线性结构指的是数据元素之间存在着“一对一”的线性关系的数据结构。
如（a0,a1,a2,.....,an）,a0为第一个元素，an为最后一个元素，此集合即为一个线性结构的集合。
相对应于线性结构，非线性结构的逻辑特征是一个结点元素可能对应多个直接前驱和多个后继。
```

#### 数组
- 线性结构
- 最大优势：支持随机访问(根据索引)
- 通过索引拿到索引对应的元素
- 数组所开辟的空间在内存里是连续分布的,所以可以直接寻找这个索引对应的偏移，直接计算出相应这个数据的存储地址， 

#### 栈
- 线性结构
- 栈有多种实现，如数组实现栈
- 栈对应的操作是数组的操作的子集 
- 只能从一端添加元素，也只能从一端取出元素
- 这一端称为栈顶
- 后进先出 LIFO
- ArrayDeque

#### 队列
- 线性结构
- 队列对应的操作是数组的操作的子集
- 只能从一端(队尾)添加元素，只能从另一端(队首)取出元素
- 先进先出 FIFO 
- 数组实现的循环队列、数组实现的不循环的队列
- 链表实现的队列

#### 链表
- 链表是真正意义上的动态数据结构，不需要处理扩容问题
- 丧失了随机访问的能力

- 栈和队列底层依托数组，通过扩容解决固定容量难题
- 栈和队列也可以通过链表实现
- 数据存储在一种单独的结构中：节点 
- 虚拟头结点：统一对头结点和其他结点的操作，到达简化逻辑的目的
- 分类：有无虚拟头结点 是否双向 是否有尾结点 是否循环
- 数组实现链表：链表结点确定的情况下

#### 递归 
- 本质上 将原来的问题转化为更小的同一问题 直到变成最基本的问题 
    - 求解最基本问题
    - 将原问题转化为更小的问题
    
    - 递归调用和子函数调用没有区别，本质是函数调用 
- 递归调用的代价：函数调用+系统栈空间
- 线性结构使用循环就可以解决
- 近乎和链表相关的所有操作，都可以使用递归的形式完成
- leetCode - 203

#### 二分搜索树
- 树结构：高效，将数据使用树结构存储后变得高效
- 树结构本身是一种天然的组织结构
- 平衡二叉树：AVL、红黑树
- 具有顺序性

- 二叉树
    - 和链表一样，具有天然递归结构：每个结点的左右孩子也是一棵二叉树的根结点, 左右子树
    - 和链表一样也是动态数据结构(在创建数据结构时就决定可以容纳多少数据)
    - 数据存储在结点中，每个结点有指向左右孩子的两个变量
    - 具有唯一根结点
    - 每个结点最多有两个孩子，一个孩子都没有的称为 叶子结点
    - 每个结点最多有一个父亲结点 根结点没有父亲结点
    - 满二叉树：除了叶子结点外都有两个孩子 
    - 二叉树不一定是"满"的
    - 一个结点或者空也是二叉树(类似链表)
- 二分搜索树
    - 是二叉树
    - 每个结点的值大于其左子树的每一个结点的值，小于其右子树的每一个结点的值 (每一棵子树也是二分搜索树)
     
    - 存储数据的局限性： 存储的元素必须具有可比较性
    - 若二分搜索树包含重复元素，只需定义：大于等于 或 小于等于
    - 在最坏的情况下退化为链表
    
    - 判断一棵二叉树是否是一棵二分搜索树：中序遍历是顺序序列
    - 顺序插入会退化为链表 
- 遍历 
    - 前序遍历：访问结点在访问其左右子树前面 非递归实现可以借助栈
    - 中序遍历：访问结点在访问其左子树和右子树的中间； 遍历的结果是所有元素排序后的结果
    - 后序遍历：访问结点在访问其左右子树后面
    
    - 深度优先遍历： 先来到最深的地方
    - 广度优先遍历(层序遍历)： 层序遍历，一层一层遍历， 每个结点都有一个深度的值(根结点为0) 借助队列; 较深度优先遍历可以更快地找到要查找的元素
    
- 后继： 某结点的后继为其右子树最小结点 即比该结点大的最小结点
- 前驱： 某结点的前驱为其左子树最大结点 即比该结点小的最大结点
- 删除二分搜索树的结点，如果要删除的结点既有左子树又有右子树，那么需要找到待删除结点的前驱或后继替代该删除结点
- 深度：根结点深度可以标志为0
- 树的高度：最大的那个深度 
- 结点高度：该结点到叶结点最长简单路径上边的数目 树的高度可以用根的高度来衡量
- 从根节点到叶子节点依次经过的节点（含根、叶节点）形成树的一条路径，最长路径的长度包含的节点数为为树的深度，即二叉树节点的层数
- 二叉树的宽度定义为具有最多结点数的层中包含的结点数


- 时间复杂度
    - 复杂度计算 涉及等比数列的求和公式 (如高度为h的满二叉树的总共的节点数)
    - 在O的定义下对数的底的大小通常忽略不计
    - 需要有一个概念：logn这个复杂度是一个非常非常快的一个时间复杂度。 很多高级的排序算法是 nlogn 这个复杂度，比n2 复杂度快了非常多倍；类比logn 和 n 的比较，两边同时乘以n.
    - 时间复杂度是 O(h) h为高度，因为增查删经历的结点数是数的高度，满二叉树的时间复杂度是 O(logn)， 二叉树的平均时间复杂度是 O(logn), 当二分搜索树退化为链表时 将到达最差的时间复杂度O(n) 即链表的时间复杂度。
    - 二叉搜索树致命的问题是最坏的情况退化为链表，即高度等于节点树(按顺序创建二分搜索树)(因为同样的数据可以对应不同的二分搜索树)，解决这个问题的方式就是创建平衡二叉树


#### 集合和映射(高级数据结构 可以通过多种不同的底层数据结构实现)
- 集合 Set：没有重复元素
    - 有序集合
        - 集合中的元素具有顺序性 基于搜索树实现
            - 平衡二叉树实现-红黑树
            - 无重复元素的二分搜索树实现，无重复元素的二分搜索树是非常好的实现"集合"的底层数据结构，时间复杂度增查删 O(h) h为树的高度，平均时间复杂度是 O(logn)，最坏情况是O(n)
    - 无序集合
        - 基于哈希表实现，
        - 基于链表实现 性能查 时间复杂度 增查删 O(n)
        
    - 多重集合：集合中的元素可以重复(可基于有重复元素的(二分)搜索树)
    
- 映射(字典(单词 --> 释意)) Map(dict) :  存储(键，值)数据对的数据结构，根据key寻找value；key是唯一的。
    - 链表实现
    - 二分搜索树实现
    
    - 有序映射
        - 键具有顺序性 基于搜索树实现
    - 无序映射
        - 键没有顺序性 基于哈希表实现
        - 基于链表实现 性能查
        
    - 多重映射
        - 具有重复键
- 联系
    - 映射可以看成是键的集合 只不过键有对应的value
    - 基于映射实现集合 映射的值为空 不管什么键，值都为空；只考虑键，整个映射就是键的集合 
    - 基于集合实现映射 重新定义集合中的元素为键值对 比较的时候通过键比较 
    - 核心的逻辑是一致的
    
    
- 映射和集合
    - 有序映射和有序集合
        - TreeMap TreeSet
        - 平衡树 红黑树 
    - 无序映射和无序集合
        - HashMap HashSet
        - 哈希表
   
#### 堆 
- 改变、限制树这个数据结构的性质，从而产生不同的数据结构，高效的解决不同的问题。堆、线段树、字典树、并查集
- 优先队列 
    - 使用最大堆实现
    - 优先队列：出队顺序和入队顺序无关，和优先级相关，优先级高者出队
    - 普通队列：先进先出，后进后出
    - 为什么使用优先队列  (动态)
        - 动态地选择优先级最高的元素，整个队列的元素是动态变化的，优先级的定义在使用优先队列的时候才定义
        - 如果元素个数固定不变，只要先排序然后再按顺序操作即可，只需要排序算法，并不需要优先队列
 
- 堆的时间复杂度： 最差时也是 O(logn)
- 堆也是一棵树
- 二叉堆：满足特殊性质的二叉树 
    - 完全二叉树(不是满二叉树)，一层一层从左向右顺序排列， 相对于满二叉树缺失结点在右下侧，(在最后一层上，右边的若干结点缺失的二叉树)
        - 完全二叉树是由满二叉树而引出来的
        - (1)所有的叶结点都出现在第k层或k-l层（层次最大的两层）
        - (2)对任一结点，如果其右子树的最大层次为L，则其左子树的最大层次为L或L+l。
    - 除了根节点，堆中某个节点的值总是小于等于(不大于)其父节点的值(最大堆-根节点值最大) (最小堆相反：其了根节点， 每个节点的值都大于等于其父节点的值)
 
- 堆 数组实现 
    - 添加操作 siftUp 时间复杂度O(logn) 
        - 首先满足完全二叉树的性质 一层一层从左向右顺序排列，也就是在数组最后添加一个元素
        - 然后满足除了根节点，堆中某个节点的值总是小于等于其父节点的值 也就说新加的元素可能需要上浮到某个位置
    - 取出元素 siftDown (只能取出堆顶的元素，即根节点的元素)  时间复杂度O(logn)
        - 首先把最后的元素和堆顶元素交换位置，再删除最后一个元素，即删除了堆顶元素
        - 然后堆顶元素下层 
    - siftUp siftDown 时间复杂度都是 O(logn)  因为是完全二叉树永远不会退化为链表，也就是高度h和节点数量之间的关系是 一定是 logn 这个级别的关系 
    
    - heapify:将任意数组整理成堆的形状(最大堆)。首先把当前数组看成是一棵完全二叉树，从最后一个非叶子节点开始从后向前(从右向左 从下往上层)执行siftDown，最后一个非叶子节点的索引等于最后一个节点的父节点的索引
        - heapify的过程算法复杂度为O(n)
        - 如果是将n个元素逐个插入到一个空堆中，算法复杂度是O(nlogn)
    - 最大堆：优先级最高的元素在根节点。因为优先级的高低是自定义的，所以当需要实现最小堆的需求(堆顶是最小元素的需求)时有两种思路，一种使用最小堆，即优先级最低的节点是根节点，依然是最小元素优先级最低；另一种是反向定义优先级的高低规则，即最小元素优先级最高，那么依然可以使用最大堆实现最小堆的需求(即堆顶是最小元素的需求)(反之亦然)。
    - 最小堆：根节点是优先级最低的节点
    - java.util.PriorityQueue 是最小堆，根节点是优先级最低的节点
    
    - d叉堆时间复杂度：O(logd(n))  ; 而二叉堆是O(log2(n))
    - 索引堆：
#### skiplist
- 本质上也是一种查找结构，用于解决算法中的查找问题（Searching），即根据给定的key，快速查到它所在的位置（或者对应的value）
- skiplist正是由多层链表的设计出来的
    - 是在有序链表的基础上发展起来的
    - 每相邻两个节点增加一个指针，让指针指向下下个节点,所有新增加的指针连成了一个新的链表，但它包含的节点个数只有原来的一半
    - 利用同样的方式，我们可以在上层新产生的链表上，继续为每相邻的两个节点增加一个指针，从而产生第三层链表
    - 当链表足够长的时候，这种多层链表的查找方式能让我们跳过很多下层节点，大大加快查找的速度
    - 实际上，按照上面生成链表的方式，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到O(log n)
    - 但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。删除数据也有同样的问题
    
- skiplist为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数(level)。
    - 比如，一个节点随机出的层数是3，那么就把它链入到第1层到第3层这三层链表中
    - 每一个节点的层数（level）是随机出来的，而且新插入一个节点不会影响其它节点的层数。插入操作只需要修改插入节点前后的指针，而不需要对很多节点都进行调整
    - 降低了插入操作的复杂度。实际上，这是skiplist的一个很重要的特性，这让它在插入性能上明显优于平衡树的方案
- 平均时间复杂度为O(logn)

- 一般查找问题的解法分为两个大类：一个是基于各种平衡树，一个是基于哈希表。但skiplist却比较特殊，它没法归属到这两大类里面。
- skiplist与平衡树、哈希表的比较
    - 从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小
    - 从算法实现难度上来比较，skiplist比平衡树要简单得多
    - 平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速
    - skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。
    - 在做范围查找的时候，平衡树比skiplist操作要复杂 ？
    - 查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。
    
- Redis 
    - 当p=1/2时，每个节点所包含的平均指针数目为2；
    - 当p=1/4时，每个节点所包含的平均指针数目为1.33。这也是Redis里的skiplist实现在空间上的开销
    - 计算随机层数的伪码
        ```
        randomLevel()
            level := 1
            // random()返回一个[0...1)的随机数
            while random() < p and level < MaxLevel do
                level := level + 1
            return level
        ```
    - 在Redis的skiplist实现中，这两个参数的取值为：
        ```
        p = 1/4
        MaxLevel = 32

        ```

### 平衡二叉树
- 平衡二叉树：对于任意一个节点，左子树和右子树的高度差的绝对值不超过1。
    - 它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。平衡二叉树的常用实现方法有红黑树、AVL、替罪羊树、Treap、伸展树等；
    - 高度和节点数量之间的关系也是O(logn)
    - 节点的高度等于左右子树最大高度加1

- 满二叉树 完全二叉树 叶子节点的深度相差不会超过1

##### AVL树 最差的情况下增删改查时间复杂度O(logn)
- AVL树：最早的自平衡二分搜索树结构, 可以自平衡不会退化为链表
- 通过左旋转和右旋转实现自平衡
- 二分搜索树新插入元素的位置都是叶子节点，新插入元素才可能导致不平衡性，不平衡的节点只可能发生在插入的叶子节点向父亲节点去找，发生在这些节点中
 - 加入节点后，沿着节点向上维护平衡性

- 平衡因子：某结点的左子树与右子树的高度(深度)差即为该结点的平衡因子，平衡二叉树上所有结点的平衡因子只可能是 -1，0 或 1。

- 节点不平衡的四种可能性
    - LL 
        - 右旋转： 插入的元素在不平衡的节点的左侧的左侧，整个树向左倾斜需要执行右旋转。
    - RR
        - 左旋转： 插入的元素在不平衡的节点的右侧的右侧，整个树向右倾斜需要执行左旋转
    - LR
        - 插入的元素在不平衡的节点的左侧的右侧
        - 先左旋转转化为LL
    - RL
        - 插入的元素在不平衡的节点的右侧的左侧
        - 先右旋转转化为RR
     
        
        
        
    
        
        
        
```
1 红黑树
牺牲严格的高度平衡，减少旋转次数，以提高性能
2 B树
节点孩子可以有多个 比红黑树高度更小 减少了检查的结点数 减少磁盘访问
3 B+树
B+跟B树不同B+树的非叶子节点不保存关键字记录的指针，只进行数据索引，这样使得B+树每个非叶子节点所能保存的关键字大大增加

B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快

B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;
```